{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d079ca8-a8db-4640-827e-4a5ca94cb28c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create a Simple Vertex AI Pipeline for Auto ML Image Classification\n",
    "\n",
    "### Step 1: Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afff242-61d0-4fb6-91cf-bea3e783a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip3 install --user google-cloud-aiplatform==1.0.0 --upgrade\n",
    "!pip3 install --user kfp google-cloud-pipeline-components==0.1.1 --upgrade\n",
    "!pip3 install --user google-cloud-aiplatform \"shapely<2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10624ed1-9a41-4ea7-a473-2b2fd18e2067",
   "metadata": {},
   "source": [
    "#### The following code restarts the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7934bf-236a-4cda-ab15-3f5b30322d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733611dd-a108-4861-80c7-5911f171deb0",
   "metadata": {},
   "source": [
    "Finally, check that you have correctly installed the packages. **The KFP SDK version should be >=1.6**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a980a-7509-40ad-8f2f-83cfd6a4308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print KFP SDK version\n",
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "!python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fa44d-4403-4ff0-93b8-f1a0205c7659",
   "metadata": {},
   "source": [
    "### Step 2: Set your project ID and bucket\n",
    "\n",
    "You will need a Google Cloud Project ID to run your pipeline, and you will need a Cloud Storage bucket to store pipeline artifacts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c67c0c-579a-4b6c-8bff-133bb1abbee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change this for your Project ID\n",
    "PROJECT_ID = \"ml-demos-dar\" \n",
    "\n",
    "# Create a Cloud Storage Bucket and put it's name below\n",
    "BUCKET_NAME=\"gs://ml-demos-dar-ai-pipeline\"\n",
    "\n",
    "# Folder is storage where pipeline artifacts will be stored\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT\n",
    "\n",
    "# Make sure jupyter is in you the PATH\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "\n",
    "# Set the Google Cloud Region\n",
    "REGION=\"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a076b1-6037-4e91-8005-62f27beebc5a",
   "metadata": {},
   "source": [
    "### Step 3: Import libraries\n",
    "\n",
    "Add the following to import the *libraries* we'll be using throughout this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21032a55-f184-4b76-a48b-240067927d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "print(\"Imported required libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d52267-7e29-4934-aa06-022b571c8497",
   "metadata": {},
   "source": [
    "### Step 4: Define the Pipeline using Google Cloud Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104cee7-d9f7-49c4-be68-0cf2aea05339",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = PROJECT_ID\n",
    "pipeline_root_path = PIPELINE_ROOT\n",
    "\n",
    "# Define the workflow of the pipeline.\n",
    "@kfp.dsl.pipeline(\n",
    "    name=\"automl-image-training-v2\",\n",
    "    pipeline_root=pipeline_root_path,)\n",
    "def pipeline(project_id: str):\n",
    "    # The first step of your workflow is a dataset generator.\n",
    "    # This step takes a Google Cloud pipeline component, providing the necessary\n",
    "    # input arguments, and uses the Python variable `ds_op` to define its\n",
    "    # output. Note that here the `ds_op` only stores the definition of the\n",
    "    # output but not the actual returned object from the execution. The value\n",
    "    # of the object is not accessible at the dsl.pipeline level, and can only be\n",
    "    # retrieved by providing it as the input to a downstream component.\n",
    "    ds_op = gcc_aip.ImageDatasetCreateOp(\n",
    "        project=project_id,\n",
    "        display_name=\"flowers\",\n",
    "        gcs_source=\"gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\",\n",
    "        import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification,\n",
    "    )\n",
    "\n",
    "    # The second step is a model training component. It takes the dataset\n",
    "    # outputted from the first step, supplies it as an input argument to the\n",
    "    # component (see `dataset=ds_op.outputs[\"dataset\"]`), and will put its\n",
    "    # outputs into `training_job_run_op`.\n",
    "    training_job_run_op = gcc_aip.AutoMLImageTrainingJobRunOp(\n",
    "        project=project_id,\n",
    "        display_name=\"dougs-flower-classification\",\n",
    "        prediction_type=\"classification\",\n",
    "        model_type=\"CLOUD\",\n",
    "        base_model=None,\n",
    "        dataset=ds_op.outputs[\"dataset\"],\n",
    "        model_display_name=\"dougs-flower-classification\",\n",
    "        training_fraction_split=0.6,\n",
    "        validation_fraction_split=0.2,\n",
    "        test_fraction_split=0.2,\n",
    "        budget_milli_node_hours=8000,\n",
    "    )\n",
    "\n",
    "    # The third and fourth step are for deploying the model.\n",
    "    create_endpoint_op = gcc_aip.EndpointCreateOp(\n",
    "        project=project_id,\n",
    "        display_name = \"create-endpoint\",\n",
    "    )\n",
    "\n",
    "    model_deploy_op = gcc_aip.ModelDeployOp(\n",
    "        model=training_job_run_op.outputs[\"model\"],\n",
    "        endpoint=create_endpoint_op.outputs['endpoint'],\n",
    "        #automatic_resources_min_replica_count=1,\n",
    "        #automatic_resources_max_replica_count=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb121e5-55c6-4bbe-83fa-b9a8057a40e8",
   "metadata": {},
   "source": [
    "### Step 5: Compile and then Submit the Pipeline to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a8522-4484-4325-91d2-925e56c5bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='image_classif_pipeline.json')\n",
    "\n",
    "\n",
    "print(\"The pipeline has been compiled and saved to the file flower_classification_pipeline.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a26a02-971d-4cba-8159-21eb1c7a91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeaa80e-551e-4c2d-af02-7192c1c65f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = aip_client.create_run_from_job_spec(\n",
    "    job_spec_path=\"image_classif_pipeline.json\",\n",
    "    pipeline_root=pipeline_root_path,\n",
    "    parameter_values={\n",
    "        'project_id': project_id\n",
    "    }  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
