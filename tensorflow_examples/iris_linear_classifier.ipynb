{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_linear_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Basic Classification: Classify Iris Flower\n",
        "\n",
        "This is a commonly used example for teaching how to build Classification ML models.\n",
        "\n",
        "The dataseet is simple. There are four training features whcih are measurements of Iris Flower sepal and petal widths and lengths. The label is the Species of the flower. \n",
        "\n",
        "For those who don't remember their middle school botany class. The petals are the colorful parts of the flowers, and the sepal are the green leaves below the petals. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8aUDIYGJ9IO"
      },
      "source": [
        "##Install and import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moB4tpEHxKB3"
      },
      "source": [
        "# Use seaborn for pairplot.\n",
        "!pip install -q seaborn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Make NumPy printouts easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xQKvCJ85kCQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh9ne3FZ-On"
      },
      "source": [
        "## Get the data\n",
        "First download and import the dataset. There are two CSV files, one for training and one for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX2FI4gZtTt"
      },
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "\n",
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train_dataset = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test_dataset = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1NUDoAYKG-W"
      },
      "source": [
        "Just display the first few records of the training data, and then the test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oY3pMPagJrO"
      },
      "source": [
        "train_dataset[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEJHhN65a2VV"
      },
      "source": [
        "test_dataset[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGH3wxbTKgjI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-Iy4ZMAIk4N"
      },
      "source": [
        "Output the columns. Note, the Species column is the label, and the rest are the features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9nhD2HTKcaj"
      },
      "source": [
        "train_dataset.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ubs136WLNp"
      },
      "source": [
        "## Inspect the data\n",
        "\n",
        "Use the Seaborn pairplot() function to review the joint distribution of the pairs of columns from the training set.\n",
        "\n",
        "You can see that there are patterns in the features that can be used to predict the species. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRKO_x8gWKv-"
      },
      "source": [
        "sns.pairplot(train_dataset[CSV_COLUMN_NAMES], diag_kind='kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gavKO_6DWRMP"
      },
      "source": [
        "The Pandas Dataframe describe() method is useful to check the overall statistics of the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi2FzC3T21jR"
      },
      "source": [
        "train_dataset.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db7Auq1yXUvh"
      },
      "source": [
        "## Split features from labels\n",
        "\n",
        "Separate the target value—the \"label\"—from the features. This label is the value that you will train the model to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2sluJdCW7jN"
      },
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('Species')\n",
        "test_labels = test_features.pop('Species')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WH5UAzejS-4"
      },
      "source": [
        "train_features[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUql-GLFjZS9"
      },
      "source": [
        "train_labels[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk2RmlqPoM9u"
      },
      "source": [
        "### Build and Train a Simple Clasification Model\n",
        "\n",
        "Note, in the first layer the activiation function (linear). The Softmax layer is used to return the probability of each class being true for each example. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssnVcKg7oMe6"
      },
      "source": [
        "classification_model = tf.keras.Sequential([\n",
        "   tf.keras.layers.Dense(8, input_dim=4, activation='linear'),\n",
        "   tf.keras.layers.Dense(3, activation='softmax'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJv3ng3ZMcSX"
      },
      "source": [
        "The model needs to be compiled prior to training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-19T02:10:47.757560Z",
          "iopub.status.busy": "2021-06-19T02:10:47.756997Z",
          "iopub.status.idle": "2021-06-19T02:10:47.762364Z",
          "shell.execute_reply": "2021-06-19T02:10:47.761965Z"
        },
        "id": "Lhan11blCaW7"
      },
      "source": [
        "classification_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "              from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "classification_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwuyTxnNMkGM"
      },
      "source": [
        "Now, train the model using the fit() function. \n",
        "\n",
        "Note, the training history is being collected in the history variable. After train, this is used to review what happened during during. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZoOYORvoTSe"
      },
      "source": [
        "%%time\n",
        "history = classification_model.fit(train_features, \n",
        "                                   train_labels, \n",
        "                                   epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdxiCbiNYK2F"
      },
      "source": [
        "## Evaluating and Testing the Model\n",
        "\n",
        "Training is complete. Now view the loss and accuracy using the history variable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDIawBaIvMQN"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.head()\n",
        "hist.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z68GzcDyuezk"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['accuracy'], label='accuracy')\n",
        "  plt.ylim([0, 2])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX2qU7TVvBEV"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUGxCtU3NfIH"
      },
      "source": [
        "Use the evaluate() function, passing in the test data, to see how well the model does at predition. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sWO3W0koYgu"
      },
      "source": [
        "test_loss, test_acc = classification_model.evaluate(test_features,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "print('\\nTest loss:', test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C57HkesDOAPm"
      },
      "source": [
        "## Using the Model for Inference\n",
        "\n",
        "Use the predict() function to get predictions from the model. Recasl the last layer was the Softmax layer. The predictions are the probabilities of each example being the species (0, 1, or 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG5qmnAk21M1"
      },
      "source": [
        "predictions = classification_model.predict(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXfeGweI24o5"
      },
      "source": [
        "predictions[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH-mSIFzXSxO"
      },
      "source": [
        "test_labels[:5]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}